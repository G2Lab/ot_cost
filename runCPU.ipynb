{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/gpfs/commons/groups/gursoy_lab/aelhussein/ot_cost/otcost_fl_rebase'\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(f'{ROOT_DIR}/code/helper')\n",
    "import pipeline as pp\n",
    "import trainers as tr\n",
    "import process_results as pr\n",
    "import data_preprocessing as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "importlib.reload(pp)\n",
    "importlib.reload(dp)\n",
    "importlib.reload(pr)\n",
    "importlib.reload(tr)\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from sklearn import metrics\n",
    "from scipy.stats import bootstrap\n",
    "from torchvision import models\n",
    "from unet import UNet\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import resample\n",
    "import nibabel as nib\n",
    "import torchio as tio\n",
    "from torch.utils.data  import DataLoader, random_split, TensorDataset, Dataset\n",
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUEEZE = ['Synthetic', 'Credit']\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(metric_name):\n",
    "    metric_mapping = {\n",
    "        'Synthetic': metrics.roc_auc_score,\n",
    "        'Credit': metrics.f1_score,\n",
    "        'Weather': metrics.r2_score}\n",
    "    return metric_mapping[metric_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(DATASET, data_num, cost):\n",
    "    if DATASET == 'Synthetic':\n",
    "        ##load data\n",
    "        X = pd.read_csv(f'{ROOT_DIR}/data/{DATASET}/data_{data_num}_{cost:.2f}.csv', sep = ' ', names = [i for i in range(13)])\n",
    "        X = X.sample(200)\n",
    "    elif DATASET == 'Credit':\n",
    "        X = pd.read_csv(f'{ROOT_DIR}/data/{DATASET}/data_{data_num}_{cost:.2f}.csv', sep = ' ', names = [i for i in range(29)])\n",
    "        X = X.sample(200)\n",
    "    elif DATASET == 'Weather':\n",
    "        X = pd.read_csv(f'{ROOT_DIR}/data/{DATASET}/data_{data_num}_{cost:.2f}.csv', sep = ' ', names = [i for i in range(124)])\n",
    "        X = X.sample(n=500)\n",
    "    ##get X and label\n",
    "    y = X.iloc[:,-1]\n",
    "    X = X.iloc[:,:-1]\n",
    "    return X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataloaders_equal(loader1, loader2):\n",
    "    for batch1, batch2 in zip(loader1, loader2):\n",
    "        data1, labels1 = batch1\n",
    "        data2, labels2 = batch2\n",
    "        if not (torch.equal(data1, data2) and torch.equal(labels1, labels2)):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(DATASET, c, n, architecture):\n",
    "    X1, y1 = loadData(DATASET, 1, c)\n",
    "    X2, y2 = loadData(DATASET, 2, c)\n",
    "    model, criterion, optimizer, lr_scheduler = createModel(n)\n",
    "    dataloader = dp.DataPreprocessor(DATASET, BATCH_SIZE)\n",
    "    if architecture == 'single':\n",
    "        train_loader, val_loader, test_loader = dataloader.preprocess(X1, y1)\n",
    "    elif architecture == 'joint':\n",
    "        train_loader, val_loader, test_loader = dataloader.preprocess_joint(X1, y1, X2, y2)\n",
    "\n",
    "    # Training hyperparameters\n",
    "    PATIENCE = 5 \n",
    "    counter = 0 \n",
    "    \n",
    "    # Train loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    early_stop = False\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            outputs = model(x)\n",
    "            if DATASET in SQUEEZE:\n",
    "                y = y.unsqueeze(1)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            train_loss += loss.item() \n",
    "        train_loss /= len(train_loader)\n",
    "        # Validation\n",
    "        model.eval() \n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                outputs = model(x)\n",
    "                if DATASET in SQUEEZE:\n",
    "                    y = y.unsqueeze(1)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        # Log\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        N = 2\n",
    "        moving_avg_val_loss = sum(val_losses[-N:]) / N\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            counter = 0 \n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            if val_loss > moving_avg_val_loss:\n",
    "                counter += 1\n",
    "                if counter >= PATIENCE:\n",
    "                    if epoch > 30:\n",
    "                        early_stop = True\n",
    "                        break\n",
    "    #Test\n",
    "    test_loss = 0\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions_list = []\n",
    "        true_labels_list = []\n",
    "        test_loss = 0\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            predictions = best_model(X)\n",
    "            if DATASET in SQUEEZE:\n",
    "                y = y.unsqueeze(1)\n",
    "            loss = criterion(predictions, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Storing the predictions and true labels\n",
    "            predictions_list.extend(predictions.cpu().numpy())\n",
    "            true_labels_list.extend(y.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        # Converting the lists to numpy arrays\n",
    "        predictions_array = np.array(predictions_list)\n",
    "        \n",
    "        # Clipping any extreme values\n",
    "        if DATASET == 'Weather':\n",
    "            predictions_array = np.clip(predictions_array, -2, 2)\n",
    "        # Set labels based on threshold (for f1 score)\n",
    "        elif DATASET == 'Credit':\n",
    "            predictions_array = (predictions_array >= 0.5).astype(int)\n",
    "        true_labels_array = np.array(true_labels_list)\n",
    "\n",
    "        # Calculating the score\n",
    "        metric_assess = get_metric(DATASET)\n",
    "        score = metric_assess(true_labels_array, predictions_array)\n",
    "    return best_model, score, train_losses, val_losses, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, DATASET, model, criterion, optimizer, lr_scheduler, device, patience = 5):\n",
    "        self.DATASET = DATASET\n",
    "        self.model = model\n",
    "        self.best_model = copy.deepcopy(model)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.EPOCHS = 300\n",
    "        self.SQUEEZE = ['Synthetic', 'Credit']\n",
    "        self.pfedme = False\n",
    "        self.ditto = False\n",
    "\n",
    "    def set_loader(self, site):\n",
    "        train_loader, val_loader, test_loader = site\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def train_one_epoch(self, site = None):\n",
    "        model, criterion, optimizer, lr_scheduler, train_loader, _, _ = self.get_objects(site)\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(x)\n",
    "            if self.DATASET in self.SQUEEZE:\n",
    "                    y = y.unsqueeze(1)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "        return train_loss / len(train_loader)\n",
    "\n",
    "    def validate(self, site = None):\n",
    "        model, criterion, optimizer, _, _, val_loader, _ = self.get_objects(site)\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                outputs = model(x)\n",
    "                if self.DATASET in self.SQUEEZE:\n",
    "                    y = y.unsqueeze(1)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item()\n",
    "        return val_loss / len(val_loader)\n",
    "\n",
    "    def test(self, site = None):\n",
    "        _, criterion, _, _, _, _, test_loader = self.get_objects(site)\n",
    "        test_loss = 0\n",
    "        self.best_model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions_list = []\n",
    "            true_labels_list = []\n",
    "            test_loss = 0\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                predictions = self.best_model(x)\n",
    "                if self.DATASET in self.SQUEEZE:\n",
    "                    y = y.unsqueeze(1)\n",
    "                loss = criterion(predictions, y)\n",
    "                test_loss += loss.item()\n",
    "                predictions_list.extend(predictions.cpu().numpy())\n",
    "                true_labels_list.extend(y.cpu().numpy())\n",
    "            test_loss /= len(test_loader)\n",
    "            predictions_array = np.array(predictions_list)\n",
    "            if self.DATASET == 'Weather':\n",
    "                predictions_array = np.clip(predictions_array, -2, 2)\n",
    "            elif self.DATASET == 'Credit':\n",
    "                predictions_array = (predictions_array >= 0.5).astype(int)\n",
    "            true_labels_array = np.array(true_labels_list)\n",
    "            metric_assess = get_metric(DATASET)\n",
    "            score = metric_assess(true_labels_array, predictions_array)\n",
    "            return test_loss, score\n",
    "\n",
    "    def check_early_stopping(self, val_loss, val_losses, epoch, site = None):\n",
    "        model, _, _, _, _, _, test_loader = self.get_objects(site)\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            N = 2\n",
    "            moving_avg_val_loss = sum(val_losses[-N:]) / N\n",
    "            if val_loss > moving_avg_val_loss:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    if epoch > 30:\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def get_metric(self):\n",
    "        metric_mapping = {\n",
    "            'Synthetic': metrics.roc_auc_score,\n",
    "            'Credit': metrics.f1_score,\n",
    "            'Weather': metrics.r2_score}\n",
    "        return metric_mapping[self.DATASET]\n",
    "\n",
    "    def get_objects(self, site_number = None):\n",
    "        if site_number == None:\n",
    "            return self.model, self.criterion, self.optimizer, self.lr_scheduler, self.train_loader, self.val_loader, self.test_loader\n",
    "        else:\n",
    "            return (self.model_1, self.criterion_1, self.optimizer_1, self.lr_scheduler_1, self.train_loader_1, self.val_loader_1, self.test_loader_1) if site_number == 1 else (self.model_2, self.criterion_2, self.optimizer_2, self.lr_scheduler_2, self.train_loader_2, self.val_loader_2, self.test_loader_2)\n",
    "    \n",
    "    def run(self):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            train_loss = self.train_one_epoch()\n",
    "            train_losses.append(train_loss)\n",
    "            val_loss = self.validate()\n",
    "            if self.check_early_stopping(val_loss, val_losses, epoch):\n",
    "                break\n",
    "            val_losses.append(val_loss)\n",
    "        test_loss, score = self.test()\n",
    "        return score, test_loss, val_losses, train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedModelTrainer(ModelTrainer):\n",
    "    def __init__(self, DATASET,  model, criterion, optimizer, lr_scheduler, device, patience = 5, pfedme = False, pfedme_reg =1e-1):\n",
    "        super().__init__(DATASET, model,criterion, optimizer, lr_scheduler, device)\n",
    "        self.model_1, self.criterion_1, self.optimizer_1, self.lr_scheduler_1 = self._clone_model()\n",
    "        self.model_2, self.criterion_2, self.optimizer_2, self.lr_scheduler_2 = self._clone_model()\n",
    "        total_samples_1, total_samples_2 = len(train_loader_1.dataset), len(train_loader_2.dataset)\n",
    "        self.weight_1 = total_samples_1 / (total_samples_1 + total_samples_2)\n",
    "        self.weight_2 = total_samples_2 / (total_samples_1 + total_samples_2)\n",
    "        self.pfedme = pfedme\n",
    "        self.pfedme_reg = pfedme_reg\n",
    "        self.ROUNDS = 5\n",
    "        self.gradient_diversity = []\n",
    "\n",
    "    def set_loader(self, site_1_data, site_2_data):\n",
    "        self.train_loader_1, self.val_loader_1, self.test_loader_1 = site_1_data\n",
    "        self.train_loader_2, self.val_loader_2, self.test_loader_2 = site_1_data\n",
    "    \n",
    "    def _clone_model(self):\n",
    "        model_clone = copy.deepcopy(self.model)\n",
    "        criterion_clone = copy.deepcopy(self.criterion)\n",
    "        optimizer_clone = type(self.optimizer)(model_clone.parameters(), **self.optimizer.defaults)\n",
    "        lr_scheduler_clone = type(self.lr_scheduler)(optimizer_clone, gamma = self.lr_scheduler.gamma)\n",
    "        return model_clone, criterion_clone, optimizer_clone, lr_scheduler_clone\n",
    "\n",
    "    def train_site_epoch(self, site):\n",
    "        model, criterion, optimizer, lr_scheduler, train_loader, _, _ = self.get_objects(site)\n",
    "        model.train()\n",
    "        for i in range(self.ROUNDS):\n",
    "            train_loss = 0\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(x)\n",
    "                if self.DATASET in self.SQUEEZE:\n",
    "                        y = y.unsqueeze(1)\n",
    "                loss = criterion(outputs, y)\n",
    "                if self.pfedme:\n",
    "                    loss = self.pfedme_loss(site, loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                train_loss += loss.item()\n",
    "        return train_loss / len(train_loader)\n",
    "   \n",
    "    def fed_avg(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            weighted_avg_param = (self.weight_1 * self.model_1.state_dict()[name] + self.weight_2 * self.model_2.state_dict()[name]) \n",
    "            self.model.state_dict()[name].copy_(weighted_avg_param)\n",
    "        self.model_1.load_state_dict(self.model.state_dict())\n",
    "        self.model_2.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def pfedme_alg(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            weighted_avg_param = (self.weight_1 * self.model_1.state_dict()[name] + self.weight_2 * self.model_2.state_dict()[name]) \n",
    "            self.model.state_dict()[name].copy_(weighted_avg_param)\n",
    "\n",
    "    def pfedme_loss(self, site, loss):\n",
    "        regularization_loss = 0\n",
    "        model, _, _, _, _, _, _ = self.get_objects(site)\n",
    "        for p, g_p in zip(model.parameters(), self.model.parameters()):\n",
    "            regularization_loss += torch.norm(p - g_p)\n",
    "        regularization_loss = self.pfedme_reg * regularization_loss\n",
    "        return regularization_loss\n",
    "\n",
    "    def get_fed_learning_algorithm(self):\n",
    "        if not self.pfedme:\n",
    "            return self.fed_avg\n",
    "        elif self.pfedme:\n",
    "            return self.pfedme_alg\n",
    "\n",
    "    def run(self):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        fed_learning = self.get_fed_learning_algorithm()\n",
    "        for epoch in range(self.EPOCHS // self.ROUNDS):\n",
    "            train_loss = self.train_site_epoch(1)\n",
    "            train_loss +=  self.train_site_epoch(2)\n",
    "            train_losses.append(train_loss)\n",
    "            fed_learning()\n",
    "            val_loss = self.validate(1)\n",
    "            val_loss += self.validate(2)\n",
    "            if self.check_early_stopping(val_loss, val_losses, epoch, 1):\n",
    "                break\n",
    "            val_losses.append(val_loss)\n",
    "        test_loss, score = self.test(1)\n",
    "        return score, test_loss, val_losses, train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DittoModelTrainer(FederatedModelTrainer):\n",
    "    def __init__(self, DATASET,  model, criterion, optimizer, lr_scheduler, device, patience = 5, reg = 0.1):\n",
    "        super().__init__(DATASET, model,criterion, optimizer, lr_scheduler, device)\n",
    "        self.model_1_s, self.criterion_1_s, self.optimizer_1_s, self.lr_scheduler_1_s = self._clone_model()\n",
    "        self.model_2_s, self.criterion_2_s, self.optimizer_2_s, self.lr_scheduler_2_s = self._clone_model()\n",
    "        self.ditto = True\n",
    "        self.reg = reg\n",
    "\n",
    "    def set_loader(self, site_1_data, site_2_data):\n",
    "        self.train_loader_1, self.val_loader_1, self.test_loader_1 = site_1_data\n",
    "        self.train_loader_2, self.val_loader_2, self.test_loader_2 = site_1_data\n",
    "\n",
    "\n",
    "    def train_site_epoch(self, site):\n",
    "        model, criterion, optimizer, lr_scheduler, train_loader, _, _ = self.get_sent_objects(site)\n",
    "        model.train()\n",
    "        for i in range(self.ROUNDS):\n",
    "            train_loss = 0\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(x)\n",
    "                if self.DATASET in self.SQUEEZE:\n",
    "                        y = y.unsqueeze(1)\n",
    "                loss = criterion(outputs, y)\n",
    "                if self.pfedme:\n",
    "                    loss = self.pfedme_loss(site, loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #lr_scheduler.step()\n",
    "                train_loss += loss.item()\n",
    "        return train_loss / len(train_loader)\n",
    "\n",
    "    def train_site_personal_epoch(self, site):\n",
    "        model_site_p, criterion_p, optimizer_site_p, lr_scheduler_site_p, train_loader, _ , _  = self.get_objects(site)\n",
    "        model_site, criterion, optimizer_site, lr_scheduler_site, _, _, _ = self.get_sent_objects(site)\n",
    "        train_loss = 0\n",
    "        for i in range(self.ROUNDS):\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                if self.DATASET in self.SQUEEZE:\n",
    "                    y = y.unsqueeze(1)\n",
    "                loss = self.ditto_loss(model_site, model_site_p, criterion_p, x, y)\n",
    "                train_loss += loss.item()\n",
    "                model_site_p.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_site_p.step()\n",
    "                lr_scheduler_site_p.step() \n",
    "            train_loss /= len(train_loader)\n",
    "        return train_loss\n",
    "    \n",
    "    def ditto_loss(self, model_site, model_site_p, criterion, x, y):\n",
    "        outputs = model_site_p(x.float())\n",
    "        loss = criterion(outputs, y)\n",
    "        regularization_loss = 0\n",
    "        for p, g_p in zip(model_site.parameters(), model_site_p.parameters()):\n",
    "            regularization_loss += torch.norm(p - g_p)\n",
    "            regularization_loss = self.reg * regularization_loss\n",
    "        loss = loss + regularization_loss\n",
    "        return loss\n",
    "\n",
    "    def get_sent_objects(self, site_number):\n",
    "        return (self.model_1_s, self.criterion_1_s, self.optimizer_1_s, self.lr_scheduler_1_s,self.train_loader_1, self.val_loader_1, self.test_loader_1 ) if site_number == 1 else (self.model_2_s, self.criterion_2_s, self.optimizer_2_s, self.lr_scheduler_2_s, self.train_loader_2, self.val_loader_2, self.test_loader_2)\n",
    "\n",
    "    def run(self):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        fed_learning = self.get_fed_learning_algorithm()\n",
    "        for epoch in range(self.EPOCHS // self.ROUNDS):\n",
    "            _ = self.train_site_epoch(1)\n",
    "            _ =  self.train_site_epoch(2)\n",
    "            train_loss = self.train_site_personal_epoch(1)\n",
    "            train_loss +=  self.train_site_personal_epoch(2)\n",
    "            train_losses.append(train_loss)\n",
    "            fed_learning()\n",
    "            val_loss = self.validate(1)\n",
    "            val_loss += self.validate(2)\n",
    "            if self.check_early_stopping(val_loss, val_losses, epoch, 1):\n",
    "                break\n",
    "            val_losses.append(val_loss)\n",
    "        test_loss, score = self.test(1)\n",
    "        return score, test_loss, val_losses, train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelRuns(DATASET, c, n):\n",
    "    scores = {'single':[], 'joint':[], 'federated':[], 'pfedme':[], 'ditto':[]}\n",
    "    test_losses = {'single':[], 'joint':[], 'federated':[], 'pfedme':[], 'ditto':[]}\n",
    "    val_losses = {'single':[], 'joint':[], 'federated':[], 'pfedme':[], 'ditto':[]}\n",
    "    train_losses = {'single':[], 'joint':[], 'federated':[], 'pfedme':[], 'ditto':[]}\n",
    "    X1, y1 = loadData(DATASET, 1, c)\n",
    "    X2, y2 = loadData(DATASET, 2, c)\n",
    "\n",
    "    for run in range(RUNS):\n",
    "        #single\n",
    "        arch = 'single'\n",
    "        model, criterion, optimizer, lr_scheduler = createModel(n)\n",
    "        dataloader = dp.DataPreprocessor(DATASET, BATCH_SIZE)\n",
    "        site_1 = dataloader.preprocess(X1, y1)\n",
    "        trainer = ModelTrainer(DATASET, model, criterion, optimizer, lr_scheduler, DEVICE)\n",
    "        trainer.set_loader(site_1)\n",
    "        scores[arch], test_losses[arch], val_losses[arch], train_losses[arch] = trainer.run()\n",
    "\n",
    "        #joint\n",
    "        arch = 'joint'\n",
    "        model, criterion, optimizer, lr_scheduler = createModel(n)\n",
    "        dataloader = dp.DataPreprocessor(DATASET, BATCH_SIZE)\n",
    "        site_joint = dataloader.preprocess_joint(X1, y1, X2, y2)\n",
    "        trainer = ModelTrainer(DATASET, model, criterion, optimizer, lr_scheduler, DEVICE)\n",
    "        trainer.set_loader(site_joint)\n",
    "        scores[arch], test_losses[arch], val_losses[arch], train_losses[arch] = trainer.run()\n",
    "\n",
    "        #federated\n",
    "        arch = 'federated'\n",
    "        model, criterion, optimizer, lr_scheduler = createModel(n)\n",
    "        dataloader = dp.DataPreprocessor(DATASET, BATCH_SIZE)\n",
    "        site_1 = dataloader.preprocess(X1, y1)\n",
    "        site_2 = dataloader.preprocess(X2, y2)\n",
    "        trainer = FederatedModelTrainer(DATASET, model, criterion, optimizer, lr_scheduler, DEVICE)\n",
    "        trainer.set_loader(site_1, site_2)\n",
    "        scores[arch], test_losses[arch], val_losses[arch], train_losses[arch] = trainer.run()\n",
    "\n",
    "        #pfedme\n",
    "        arch = 'pfedme'\n",
    "        model, criterion, optimizer, lr_scheduler = createModel(n)\n",
    "        dataloader = dp.DataPreprocessor(DATASET, BATCH_SIZE)\n",
    "        site_1 = dataloader.preprocess(X1, y1)\n",
    "        site_2 = dataloader.preprocess(X2, y2)\n",
    "        trainer = FederatedModelTrainer(DATASET, model, criterion, optimizer, lr_scheduler, DEVICE, pfedme = True)\n",
    "        trainer.set_loader(site_1, site_2)\n",
    "        scores[arch], test_losses[arch], val_losses[arch], train_losses[arch] = trainer.run()\n",
    "        \n",
    "        #ditto\n",
    "        arch = 'ditto'\n",
    "        model, criterion, optimizer, lr_scheduler = createModel(n)\n",
    "        dataloader = dp.DataPreprocessor(DATASET, BATCH_SIZE)\n",
    "        site_1 = dataloader.preprocess(X1, y1)\n",
    "        site_2 = dataloader.preprocess(X2, y2)\n",
    "        trainer = DittoModelTrainer(DATASET, model, criterion, optimizer, lr_scheduler, DEVICE)\n",
    "        trainer.set_loader(site_1, site_2)\n",
    "        scores[arch], test_losses[arch], val_losses[arch], train_losses[arch] = trainer.run()\n",
    "\n",
    "    return scores, train_losses, val_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAnalysis(DATASET, costs, n):\n",
    "    results_scores = {}\n",
    "    results_train_losses = {}\n",
    "    results_val_losses = {}\n",
    "    results_test_losses = {}\n",
    "    for c in costs:\n",
    "        results_scores[c], results_train_losses[c], results_val_losses[c], results_test_losses[c] =  modelRuns(DATASET, c, n)\n",
    "\n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_scores_full.pkl', 'wb') as f:\n",
    "        pickle.dump(results_scores, f)\n",
    "    \n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_train_losses_full.pkl', 'wb') as f:\n",
    "        pickle.dump(results_train_losses, f)\n",
    "\n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_val_losses_full.pkl', 'wb') as f:\n",
    "        pickle.dump(results_val_losses, f)\n",
    "    \n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_test_losses_full.pkl', 'wb') as f:\n",
    "        pickle.dump(results_test_losses, f)\n",
    "\n",
    "    return results_scores, results_train_losses, results_val_losses, results_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelRuns(DATASET, c, n, architecture):\n",
    "    scores = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    for run in range(RUNS):\n",
    "        best_model, score, train_losses, val_losses, test_loss = runModel(DATASET, c, n, architecture)\n",
    "        scores.append(score)\n",
    "        train_loss_list.append(train_losses)\n",
    "        val_loss_list.append(val_losses)\n",
    "        test_loss_list.append(test_loss)\n",
    "    return scores, train_loss_list, val_loss_list, test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAnalysis(DATASET, costs, n):\n",
    "    results_scores = {}\n",
    "    results_train_losses = {}\n",
    "    results_val_losses = {}\n",
    "    results_test_losses = {}\n",
    "    for c in costs:\n",
    "        results_scores[c] = {}\n",
    "        results_train_losses[c] = {}\n",
    "        results_val_losses[c] = {}\n",
    "        results_test_losses[c] = {}\n",
    "        for architecture in ['single', 'joint']:\n",
    "            scores, train_loss_list, val_loss_list, test_loss_list = modelRuns(DATASET, c, n, architecture)\n",
    "            results_scores[c][architecture] = scores\n",
    "            results_train_losses[c][architecture] = train_loss_list\n",
    "            results_val_losses[c][architecture] = val_loss_list\n",
    "            results_test_losses[c][architecture] = test_loss_list\n",
    "    '''\n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_scores.pkl', 'wb') as f:\n",
    "        pickle.dump(results_scores, f)\n",
    "    \n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_train_losses.pkl', 'wb') as f:\n",
    "        pickle.dump(results_train_losses, f)\n",
    "\n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_val_losses.pkl', 'wb') as f:\n",
    "        pickle.dump(results_val_losses, f)\n",
    "    \n",
    "    with open(f'{ROOT_DIR}/results/{DATASET}_test_losses.pkl', 'wb') as f:\n",
    "        pickle.dump(results_test_losses, f)\n",
    "    '''\n",
    "\n",
    "\n",
    "    return results_scores, results_train_losses, results_val_losses, results_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(auc_scores,train_loss_list, val_loss_list, test_loss_list, data_type):    \n",
    "    # Plotting Train Losses\n",
    "    plt.figure(figsize = (5,3))\n",
    "    # Determine the maximum length\n",
    "    train_loss_list = [t[5:] for t in train_loss_list]\n",
    "    val_loss_list = [v[5:] for v in val_loss_list]\n",
    "    max_length = max(max(len(t) for t in train_loss_list), max(len(v) for v in val_loss_list))\n",
    "    # Pad the shorter lists with np.nan\n",
    "    train_losses_padded = [np.pad(t, (0, max_length - len(t)), 'constant', constant_values=np.nan) for t in train_loss_list]\n",
    "    val_losses_padded = [np.pad(v, (0, max_length - len(v)), 'constant', constant_values=np.nan) for v in val_loss_list]\n",
    "    train_losses = pd.DataFrame(train_losses_padded)\n",
    "    val_losses = pd.DataFrame(val_losses_padded)\n",
    "    sns.lineplot(train_losses.mean(axis = 0), label = 'Train', alpha = 0.5)\n",
    "    sns.lineplot(val_losses.mean(axis = 0), label = 'Val', alpha = 0.5)\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "                super(Feedforward, self).__init__()\n",
    "                self.input_size = input_size\n",
    "                self.hidden_size = [56, 6]\n",
    "                self.fc = torch.nn.Sequential(nn.Linear(self.input_size, self.hidden_size[0]),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Dropout(0.3),\n",
    "                                                nn.Linear(self.hidden_size[0], self.hidden_size[1]),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Linear(self.hidden_size[1], 1))\n",
    "                self.sigmoid = torch.nn.Sigmoid()\n",
    "                for layer in self.fc:\n",
    "                        if isinstance(layer, nn.Linear):\n",
    "                                nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "                                nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "                output = self.fc(x)\n",
    "                output = self.sigmoid(output)\n",
    "                return output\n",
    "        \n",
    "def createModel(n):\n",
    "    model = Feedforward(n)\n",
    "    model.to(DEVICE)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=0.8)\n",
    "    return model, criterion, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 2000\n",
    "RUNS = 100\n",
    "DATASET = 'Synthetic'\n",
    "METRIC_TEST = 'AUC'\n",
    "LEARNING_RATE = 5e-2\n",
    "costs = [0.03, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60]\n",
    "n = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scores, results_train_losses, results_val_losses, results_test_losses = runAnalysis(DATASET, costs, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "                super(Feedforward, self).__init__()\n",
    "                self.input_size = input_size\n",
    "                self.hidden_size  = [56,56,28]\n",
    "                self.fc = nn.Sequential(\n",
    "                        nn.Linear(self.input_size, self.hidden_size[0]),\n",
    "                        nn.BatchNorm1d(self.hidden_size[0]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(self.hidden_size[0], self.hidden_size[1]),\n",
    "                        nn.BatchNorm1d(self.hidden_size[1]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(self.hidden_size[1], self.hidden_size[2]),\n",
    "                        nn.BatchNorm1d(self.hidden_size[2]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(self.hidden_size[2], 1)\n",
    "                )\n",
    "                for layer in self.fc:\n",
    "                    if isinstance(layer, nn.Linear):\n",
    "                            nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "                            nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "                self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        def forward(self, x):\n",
    "                output = self.fc(x)\n",
    "                #output = self.sigmoid(output)\n",
    "                return output\n",
    "        \n",
    "def createModel(n):\n",
    "    model = Feedforward(28)\n",
    "    model.to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    #criterion = WeightedFocalLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "    return model, criterion, optimizer, lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 2000\n",
    "RUNS = 100\n",
    "DATASET = 'Credit'\n",
    "METRIC_TEST = 'AUPRC'\n",
    "LEARNING_RATE = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = [0.12, 0.23, 0.30, 0.40]\n",
    "n = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scores, results_train_losses, results_val_losses, results_test_losses = runAnalysis(DATASET, costs, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "                super(Feedforward, self).__init__()\n",
    "                self.input_size = input_size\n",
    "                self.hidden_size  = [123,123,50]\n",
    "                self.fc = nn.Sequential(\n",
    "                        nn.Linear(self.input_size, self.hidden_size[0]),\n",
    "                        nn.BatchNorm1d(self.hidden_size[0]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(self.hidden_size[0], self.hidden_size[1]),\n",
    "                        nn.BatchNorm1d(self.hidden_size[1]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(self.hidden_size[1], self.hidden_size[2]),\n",
    "                        nn.BatchNorm1d(self.hidden_size[2]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(self.hidden_size[2], 1)\n",
    "                )\n",
    "                for layer in self.fc:\n",
    "                        if isinstance(layer, nn.Linear):\n",
    "                                nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "                                nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "                output = self.fc(x)\n",
    "                return output\n",
    "        \n",
    "def createModel(n):\n",
    "    model = Feedforward(n)\n",
    "    model.to(DEVICE)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=0.8)\n",
    "    return model, criterion, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4000\n",
    "RUNS = 100\n",
    "DATASET = 'Weather'\n",
    "METRIC_TEST = 'R2'\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = [0.11, 0.19, 0.30, 0.40, 0.48]\n",
    "c = costs[0]\n",
    "n = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scores, results_train_losses, results_val_losses, results_test_losses = runAnalysis(DATASET, costs, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
